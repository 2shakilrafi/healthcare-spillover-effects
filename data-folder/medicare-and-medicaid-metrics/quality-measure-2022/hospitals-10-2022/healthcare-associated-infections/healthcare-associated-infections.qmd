---
title: "outpatient imaging"
format: html
editor: visual
---

# State Level

```{r}
library(tidyverse)
library(janitor)

state <- read_csv("healthcare-associated-infections-state.csv") |>
  clean_names() |>
  select(state, measure_id, score) |>
  mutate(
    state = str_to_lower(state),
    score = as.numeric(score)
  ) |>
  pivot_wider(
    names_from = measure_id,
    values_from = score
  )

```

```{r}
library(tidyverse)
library(janitor)

# Two-letter to full state name mapping
state_lookup <- tibble(
  state = state.abb,
  full_state = tolower(state.name)
)

df_clean <- read_csv("outpatient-imaging-efficiency-state.csv") %>%
  clean_names() %>%
  select(state, measure_id, score) %>%
  left_join(state_lookup, by = c("state" = "state")) %>%
  select(full_state, measure_id, score) %>%
  rename(state = full_state) %>%
  mutate(score = as.numeric(score)) %>%
  pivot_wider(
    names_from = measure_id,
    values_from = score
  )

```

```{r}
library(tidyverse)
library(janitor)

# State abbreviation to full name mapping
state_lookup <- tibble(
  state = state.abb,
  full_state = tolower(state.name)
)

state <- read_csv("outpatient-imaging-efficiency-state.csv") %>%
  clean_names() %>%
  select(state, measure_id, score) %>%
  left_join(state_lookup, by = c("state" = "state")) %>%
  select(full_state, measure_id, score) %>%
  rename(state = full_state) %>%
  mutate(score = as.numeric(score)) %>%
  filter(!is.na(state)) %>%
  pivot_wider(
    names_from = measure_id,
    values_from = score
  )

```

```{r}
us_map <- map_data("state")

# Merge the cleaned data
map_df <- left_join(us_map, state, by = c("region" = "state"))

# Identify all OP_* columns
metrics <- names(df_clean)[-1]  # everything except 'state'

# Loop through each metric and plot
for (metric in metrics) {
  print(
    ggplot(map_df, aes(long, lat, group = group, fill = .data[[metric]])) +
      geom_polygon(color = "white", size = 0.2) +
      scale_fill_viridis_c(na.value = "grey80") +
      coord_map("albers", lat0 = 39, lat1 = 45) +
      labs(
        title = paste("Choropleth of", metric),
        fill = metric
      ) +
      theme_minimal()
  )
}
```

# Hospital Level

## Moran's I

```{r}
# install.packages(c("tidyverse","sf","spdep","janitor"))
library(tidyverse)
library(sf)
library(spdep)
library(janitor)

# 1. Read & clean
df <- read_csv("geocoded_hospital.csv") %>%
  drop_na(lat, lon) %>%        # need real coords
  clean_names()                # makes OP-10 → op_10 etc.

# 2. Make an sf object and grab raw coords matrix
sf_df <- st_as_sf(df, coords = c("lon","lat"), crs = 4326)
coords <- st_coordinates(sf_df)

# 3. Identify your OP metrics
op_cols <- df %>% select(starts_with("op_")) %>% names()

# 4. Loop & compute Moran’s I by rebuilding neighbours on non-NA points
moran_results <- map_df(op_cols, function(m) {
  vals <- sf_df[[m]]
  keep <- which(!is.na(vals))
  
  if (length(keep) < 3) {
    return(tibble(metric = m, I_stat = NA_real_, p_value = NA_real_))
  }
  
  # Rebuild 5-NN just on the hospitals with data
  coords_sub <- coords[keep, ]
  nb_sub     <- knn2nb(knearneigh(coords_sub, k = 5))
  lw_sub     <- nb2listw(nb_sub, style = "W", zero.policy = TRUE)
  
  mi <- moran.test(vals[keep], lw_sub, zero.policy = TRUE)
  
  tibble(
    metric  = m,
    I_stat  = unname(mi$estimate["Moran I statistic"]),
    p_value = mi$p.value
  )
})

print(moran_results)

```

## SAR

```{r}
# install.packages(c("tidyverse","sf","spdep","spatialreg","janitor"))
library(tidyverse)
library(sf)
library(spdep)
library(spatialreg)
library(janitor)

# 1. Read, clean, & make sf
df <- read_csv("geocoded_hospital.csv") %>%
  drop_na(lat, lon) %>% 
  clean_names()         # OP-10 → op_10, etc.

sf_df  <- st_as_sf(df, coords = c("lon","lat"), crs = 4326)
coords <- st_coordinates(sf_df)

# 2. Identify your OP metrics
op_cols <- df %>% select(starts_with("op_")) %>% names()

# 3. Prepare a results table
sar_results <- tibble(
  metric    = character(),
  rho       = double(),   # spatial‐lag coefficient
  LR_stat   = double(),   # likelihood‐ratio test statistic
  LR_df     = double(),
  LR_pvalue = double()    # p-value for LR test of rho ≠ 0
)

# 4. Loop: build 5-NN weights on the non-missing subset, fit SAR
for (m in op_cols) {
  vals <- df[[m]]
  keep <- which(!is.na(vals))
  if (length(keep) < 10) {     # skip if too few points
    sar_results <- sar_results %>%
      add_row(metric = m, rho = NA, LR_stat = NA, LR_df = NA, LR_pvalue = NA)
    next
  }
  
  # subset data + coords
  df_sub    <- df[keep, ]
  coords_sub<- coords[keep, ]
  
  # 5-NN on just those points
  nb_sub <- knn2nb(knearneigh(coords_sub, k = 5))
  lw_sub <- nb2listw(nb_sub, style = "W", zero.policy = TRUE)
  
  # intercept-only SAR: Y = ρ W Y + 1·β0 + ε
  formula <- as.formula(paste(m, "~ 1"))
  sar_mod <- lagsarlm(formula, data = df_sub, listw = lw_sub, zero.policy = TRUE)
  sm      <- summary(sar_mod)
  
  # pull out what we want
  sar_results <- sar_results %>%
    add_row(
      metric    = m,
      rho       = sm$rho,
      LR_stat   = sm$LR1[1],
      LR_df     = sm$LR1[2],
      LR_pvalue = sm$LR1[3]
    )
}

print(sar_results)

```
